优化器：Adadelta
[0.0, 0.25, 0.5714285714285714, 0.7, 0.7692307692307693, 0.8125, 0.7894736842105263, 0.7727272727272727, 0.8, 0.7857142857142857, 0.8064516129032258, 0.7941176470588235, 0.8108108108108109, 0.8, 0.813953488372093, 0.8260869565217391, 0.8163265306122449, 0.8076923076923077, 0.8181818181818182]
[7.1614532470703125, 4.581726551055908, 2.6564409732818604, 1.7111725807189941, 1.5463484525680542, 1.2161059379577637, 1.2648366689682007, 0.940434455871582, 0.9902883768081665, 1.0047650337219238, 0.7526599764823914, 0.7408321499824524, 0.772696852684021, 0.7259504199028015, 0.686862587928772, 0.7908170819282532, 0.5546911954879761, 0.6880810856819153, 0.6794933080673218]
[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54]


优化器：SGD
[0.0, 0.5, 0.5714285714285714, 0.7, 0.7692307692307693, 0.8125, 0.8421052631578947, 0.8636363636363636, 0.88, 0.8214285714285714, 0.8387096774193549, 0.8529411764705882, 0.8648648648648649, 0.875, 0.8837209302325582, 0.8913043478260869, 0.8979591836734694, 0.9038461538461539, 0.9090909090909091]
[6.233266830444336, 3.0524377822875977, 0.9557873606681824, 1.2667416334152222, 0.7429953813552856, 0.9714170098304749, 0.7208793759346008, 0.6704448461532593, 1.0461616516113281, 0.5950726270675659, 0.8645665645599365, 0.5255600810050964, 0.4606381356716156, 0.46381476521492004, 0.4085111916065216, 0.6228423714637756, 0.8293837308883667, 0.6084031462669373, 0.4679167866706848]
[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54]


优化器：Adam
[0.0, 0.5, 0.2857142857142857, 0.4, 0.5384615384615384, 0.4375, 0.42105263157894735, 0.5, 0.52, 0.4642857142857143, 0.41935483870967744, 0.47058823529411764, 0.4594594594594595, 0.425, 0.3953488372093023, 0.41304347826086957, 0.3877551020408163, 0.36538461538461536, 0.36363636363636365]
[7.410924911499023, 3.0081939697265625, 1.610795497894287, 1.2693580389022827, 1.4009594917297363, 1.2465933561325073, 1.119574785232544, 1.2204581499099731, 1.0583502054214478, 1.2623634338378906, 1.1138956546783447, 1.1442033052444458, 1.0653709173202515, 1.252795934677124, 1.1630675792694092, 1.1269960403442383, 1.1344479322433472, 1.1092109680175781, 1.111085295677185]
[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54]


优化器：Adagrad
[0.0, 0.25, 0.2857142857142857, 0.4, 0.38461538461538464, 0.4375, 0.42105263157894735, 0.4090909090909091, 0.4, 0.42857142857142855, 0.41935483870967744, 0.38235294117647056, 0.35135135135135137, 0.325, 0.3023255813953488, 0.2826086956521739, 0.2857142857142857, 0.3076923076923077, 0.2909090909090909]
[7.572462558746338, 2.587477445602417, 1.191322922706604, 1.227598786354065, 1.302661657333374, 1.181738018989563, 1.2283129692077637, 1.2349432706832886, 1.1140168905258179, 1.139516830444336, 1.098788857460022, 1.1721374988555908, 1.1382123231887817, 1.1631629467010498, 1.1333812475204468, 0.9443783164024353, 1.2117011547088623, 1.0915526151657104, 1.1845709085464478]
[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48, 51, 54]



D:\python312\python.exe C:\Users\xincun\Desktop\graduation_project_v4\DetectMModel\TransformerModel\transformer_v3.py
正在统计序列最大长度...: 100%|██████████| 2928/2928 [00:00<00:00, 279067.47it/s]
huqinsong 416 999
训练轮数：1
Epoch: 1 batch index: 1/56 loss = 7.060586 acc: 0.0 %
Epoch: 1 batch index: 2/56 loss = 6.254182 acc: 0.0 %
Epoch: 1 batch index: 3/56 loss = 5.480430 acc: 0.0 %
Epoch: 1 batch index: 4/56 loss = 4.739583 acc: 0.0 %
Epoch: 1 batch index: 5/56 loss = 4.126587 acc: 20.0 %
Epoch: 1 batch index: 6/56 loss = 3.663224 acc: 33.33333333333333 %
Epoch: 1 batch index: 7/56 loss = 3.114971 acc: 42.857142857142854 %
Epoch: 1 batch index: 8/56 loss = 2.738878 acc: 50.0 %
Epoch: 1 batch index: 9/56 loss = 2.440635 acc: 55.55555555555556 %
Epoch: 1 batch index: 10/56 loss = 2.038999 acc: 60.0 %
Epoch: 1 batch index: 11/56 loss = 1.872831 acc: 63.63636363636363 %
Epoch: 1 batch index: 12/56 loss = 1.840492 acc: 66.66666666666666 %
Epoch: 1 batch index: 13/56 loss = 1.636480 acc: 69.23076923076923 %
Epoch: 1 batch index: 14/56 loss = 1.467819 acc: 71.42857142857143 %
Epoch: 1 batch index: 15/56 loss = 1.215795 acc: 73.33333333333333 %
Epoch: 1 batch index: 16/56 loss = 1.520160 acc: 75.0 %
Epoch: 1 batch index: 17/56 loss = 1.406980 acc: 76.47058823529412 %
Epoch: 1 batch index: 18/56 loss = 1.045713 acc: 77.77777777777779 %
Epoch: 1 batch index: 19/56 loss = 1.262501 acc: 78.94736842105263 %
Epoch: 1 batch index: 20/56 loss = 1.141889 acc: 75.0 %
Epoch: 1 batch index: 21/56 loss = 1.170713 acc: 76.19047619047619 %
Epoch: 1 batch index: 22/56 loss = 1.131960 acc: 77.27272727272727 %
Epoch: 1 batch index: 23/56 loss = 0.987469 acc: 78.26086956521739 %
Epoch: 1 batch index: 24/56 loss = 1.085962 acc: 75.0 %
Epoch: 1 batch index: 25/56 loss = 1.239597 acc: 76.0 %
Epoch: 1 batch index: 26/56 loss = 0.984177 acc: 76.92307692307693 %
Epoch: 1 batch index: 27/56 loss = 0.907229 acc: 77.77777777777779 %
Epoch: 1 batch index: 28/56 loss = 0.869427 acc: 78.57142857142857 %
Epoch: 1 batch index: 29/56 loss = 0.950858 acc: 79.3103448275862 %
Epoch: 1 batch index: 30/56 loss = 0.903934 acc: 80.0 %
Epoch: 1 batch index: 31/56 loss = 0.851692 acc: 80.64516129032258 %
Epoch: 1 batch index: 32/56 loss = 0.832430 acc: 81.25 %
Epoch: 1 batch index: 33/56 loss = 0.777373 acc: 81.81818181818183 %
Epoch: 1 batch index: 34/56 loss = 0.834741 acc: 82.35294117647058 %
Epoch: 1 batch index: 35/56 loss = 0.891692 acc: 80.0 %
Epoch: 1 batch index: 36/56 loss = 0.668764 acc: 80.55555555555556 %
Epoch: 1 batch index: 37/56 loss = 0.940981 acc: 81.08108108108108 %
Epoch: 1 batch index: 38/56 loss = 0.714559 acc: 81.57894736842105 %
Epoch: 1 batch index: 39/56 loss = 0.895196 acc: 82.05128205128204 %
Epoch: 1 batch index: 40/56 loss = 0.796746 acc: 80.0 %
Epoch: 1 batch index: 41/56 loss = 0.744113 acc: 80.48780487804879 %
Epoch: 1 batch index: 42/56 loss = 0.713434 acc: 80.95238095238095 %
Epoch: 1 batch index: 43/56 loss = 0.681015 acc: 81.3953488372093 %
Epoch: 1 batch index: 44/56 loss = 0.766804 acc: 81.81818181818183 %
Epoch: 1 batch index: 45/56 loss = 0.719061 acc: 82.22222222222221 %
Epoch: 1 batch index: 46/56 loss = 0.717538 acc: 82.6086956521739 %
Epoch: 1 batch index: 47/56 loss = 0.700143 acc: 82.97872340425532 %
Epoch: 1 batch index: 48/56 loss = 0.713304 acc: 83.33333333333334 %
Epoch: 1 batch index: 49/56 loss = 0.529849 acc: 83.6734693877551 %
Epoch: 1 batch index: 50/56 loss = 0.672856 acc: 84.0 %
Epoch: 1 batch index: 51/56 loss = 0.861951 acc: 84.31372549019608 %
Epoch: 1 batch index: 52/56 loss = 0.567966 acc: 84.61538461538461 %
Epoch: 1 batch index: 53/56 loss = 0.631584 acc: 83.01886792452831 %
Epoch: 1 batch index: 54/56 loss = 0.579827 acc: 81.48148148148148 %
Epoch: 1 batch index: 55/56 loss = 0.564161 acc: 81.81818181818183 %
Epoch: 1 batch index: 56/56 loss = 0.664141 acc: 82.14285714285714 %
训练完1轮
训练轮数：2
Epoch: 2 batch index: 1/56 loss = 0.741431 acc: 0.0 %
Epoch: 2 batch index: 2/56 loss = 0.580014 acc: 50.0 %
Epoch: 2 batch index: 3/56 loss = 0.552689 acc: 66.66666666666666 %
Epoch: 2 batch index: 4/56 loss = 0.706869 acc: 75.0 %
Epoch: 2 batch index: 5/56 loss = 0.542676 acc: 80.0 %
Epoch: 2 batch index: 6/56 loss = 0.575248 acc: 83.33333333333334 %
Epoch: 2 batch index: 7/56 loss = 0.582955 acc: 85.71428571428571 %
Epoch: 2 batch index: 8/56 loss = 0.636514 acc: 87.5 %
Epoch: 2 batch index: 9/56 loss = 0.529820 acc: 88.88888888888889 %
Epoch: 2 batch index: 10/56 loss = 0.565112 acc: 90.0 %
Epoch: 2 batch index: 11/56 loss = 0.703237 acc: 90.9090909090909 %
Epoch: 2 batch index: 12/56 loss = 0.590142 acc: 91.66666666666666 %
Epoch: 2 batch index: 13/56 loss = 0.652262 acc: 92.3076923076923 %
Epoch: 2 batch index: 14/56 loss = 0.591270 acc: 92.85714285714286 %
Epoch: 2 batch index: 15/56 loss = 0.544563 acc: 93.33333333333333 %
Epoch: 2 batch index: 16/56 loss = 0.553226 acc: 93.75 %
Epoch: 2 batch index: 17/56 loss = 0.628038 acc: 88.23529411764706 %
Epoch: 2 batch index: 18/56 loss = 0.615348 acc: 88.88888888888889 %
Epoch: 2 batch index: 19/56 loss = 0.550698 acc: 89.47368421052632 %
Epoch: 2 batch index: 20/56 loss = 0.559096 acc: 90.0 %
Epoch: 2 batch index: 21/56 loss = 0.567585 acc: 90.47619047619048 %
Epoch: 2 batch index: 22/56 loss = 0.585938 acc: 90.9090909090909 %
Epoch: 2 batch index: 23/56 loss = 0.521092 acc: 91.30434782608695 %
Epoch: 2 batch index: 24/56 loss = 0.546828 acc: 91.66666666666666 %
Epoch: 2 batch index: 25/56 loss = 0.593522 acc: 92.0 %
Epoch: 2 batch index: 26/56 loss = 0.534847 acc: 92.3076923076923 %
Epoch: 2 batch index: 27/56 loss = 0.478988 acc: 92.5925925925926 %
Epoch: 2 batch index: 28/56 loss = 0.600084 acc: 92.85714285714286 %
Epoch: 2 batch index: 29/56 loss = 0.468847 acc: 93.10344827586206 %
Epoch: 2 batch index: 30/56 loss = 0.515782 acc: 93.33333333333333 %
Epoch: 2 batch index: 31/56 loss = 0.555332 acc: 93.54838709677419 %
Epoch: 2 batch index: 32/56 loss = 0.513341 acc: 93.75 %
Epoch: 2 batch index: 33/56 loss = 0.544936 acc: 93.93939393939394 %
Epoch: 2 batch index: 34/56 loss = 0.517582 acc: 94.11764705882352 %
Epoch: 2 batch index: 35/56 loss = 0.447390 acc: 94.28571428571428 %
Epoch: 2 batch index: 36/56 loss = 0.523587 acc: 94.44444444444444 %
Epoch: 2 batch index: 37/56 loss = 0.477139 acc: 94.5945945945946 %
Epoch: 2 batch index: 38/56 loss = 0.465491 acc: 94.73684210526315 %
Epoch: 2 batch index: 39/56 loss = 0.427263 acc: 94.87179487179486 %
Epoch: 2 batch index: 40/56 loss = 0.478939 acc: 95.0 %
Epoch: 2 batch index: 41/56 loss = 0.484967 acc: 95.1219512195122 %
Epoch: 2 batch index: 42/56 loss = 0.586411 acc: 95.23809523809523 %
Epoch: 2 batch index: 43/56 loss = 0.491312 acc: 95.34883720930233 %
Epoch: 2 batch index: 44/56 loss = 0.504131 acc: 95.45454545454545 %
Epoch: 2 batch index: 45/56 loss = 0.477052 acc: 95.55555555555556 %
Epoch: 2 batch index: 46/56 loss = 0.517629 acc: 95.65217391304348 %
Epoch: 2 batch index: 47/56 loss = 0.409462 acc: 95.74468085106383 %
Epoch: 2 batch index: 48/56 loss = 0.481654 acc: 95.83333333333334 %
Epoch: 2 batch index: 49/56 loss = 0.455660 acc: 95.91836734693877 %
Epoch: 2 batch index: 50/56 loss = 0.405360 acc: 96.0 %
Epoch: 2 batch index: 51/56 loss = 0.559200 acc: 96.07843137254902 %
Epoch: 2 batch index: 52/56 loss = 0.432893 acc: 96.15384615384616 %
Epoch: 2 batch index: 53/56 loss = 0.436288 acc: 96.22641509433963 %
Epoch: 2 batch index: 54/56 loss = 0.523384 acc: 96.29629629629629 %
Epoch: 2 batch index: 55/56 loss = 0.460290 acc: 96.36363636363636 %
Epoch: 2 batch index: 56/56 loss = 0.515040 acc: 96.42857142857143 %
训练完1轮
训练轮数：3
Epoch: 3 batch index: 1/56 loss = 0.462058 acc: 100.0 %
Epoch: 3 batch index: 2/56 loss = 0.455047 acc: 100.0 %
Epoch: 3 batch index: 3/56 loss = 0.488115 acc: 100.0 %
Epoch: 3 batch index: 4/56 loss = 0.497354 acc: 100.0 %
Epoch: 3 batch index: 5/56 loss = 0.459791 acc: 100.0 %
Epoch: 3 batch index: 6/56 loss = 0.445226 acc: 100.0 %
Epoch: 3 batch index: 7/56 loss = 0.414959 acc: 100.0 %
Epoch: 3 batch index: 8/56 loss = 0.371092 acc: 100.0 %
Epoch: 3 batch index: 9/56 loss = 0.427113 acc: 100.0 %
Epoch: 3 batch index: 10/56 loss = 0.397682 acc: 100.0 %
Epoch: 3 batch index: 11/56 loss = 0.343969 acc: 100.0 %
Epoch: 3 batch index: 12/56 loss = 0.499267 acc: 100.0 %
Epoch: 3 batch index: 13/56 loss = 0.396723 acc: 100.0 %
Epoch: 3 batch index: 14/56 loss = 0.455296 acc: 100.0 %
Epoch: 3 batch index: 15/56 loss = 0.441786 acc: 100.0 %
Epoch: 3 batch index: 16/56 loss = 0.403836 acc: 100.0 %
Epoch: 3 batch index: 17/56 loss = 0.418247 acc: 100.0 %
Epoch: 3 batch index: 18/56 loss = 0.458491 acc: 100.0 %
Epoch: 3 batch index: 19/56 loss = 0.441832 acc: 100.0 %
Epoch: 3 batch index: 20/56 loss = 0.417388 acc: 100.0 %
Epoch: 3 batch index: 21/56 loss = 0.476611 acc: 100.0 %
Epoch: 3 batch index: 22/56 loss = 0.425551 acc: 100.0 %
Epoch: 3 batch index: 23/56 loss = 0.411229 acc: 100.0 %
Epoch: 3 batch index: 24/56 loss = 0.378320 acc: 100.0 %
Epoch: 3 batch index: 25/56 loss = 0.444001 acc: 100.0 %
Epoch: 3 batch index: 26/56 loss = 0.461882 acc: 100.0 %
